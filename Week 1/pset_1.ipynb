{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### NX-414: Brain-like computation and intelligence, Spring 2026\n",
    "\n",
    "Notebook prepared by Bartlomiej Borzyszkowski & Abdulkadir Gokce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "# Week 1 - Learning a sparse code for natural images\n",
    "### Table of Contents<span class=\"tocSkip\"></span>\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>Introduction</a></span></li>\n",
    "    <li><span><a href=\"#2.-Image-representation\" data-toc-modified-id=\"Image-representation-2\"><span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>Image representation</a></span></li>\n",
    "    <li><span><a href=\"#3.-Principal-Components-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Components-Analysis-(PCA)-3\"><span class=\"toc-item-num\">3.&nbsp;&nbsp;</span>Principal Components Analysis (PCA)</a></span></li>\n",
    "    <li><span><a href=\"#4.-Sparse-coding-network\" data-toc-modified-id=\"Sparse-coding-network-4\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>Sparse coding network</a></span></li> \n",
    "    <li><span><a href=\"#5.-Run-simulation\" data-toc-modified-id=\"Run-simulation-5\"><span class=\"toc-item-num\">5.&nbsp;&nbsp;</span>Run simulation</a></span></li> \n",
    "    <li><span><a href=\"#6.-Evaluate-performance\" data-toc-modified-id=\"Evaluate-performance-6\"><span class=\"toc-item-num\">6.&nbsp;&nbsp;</span>Evaluate performance</a></span></li> \n",
    "    <li><span><a href=\"#7.-Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7.&nbsp;&nbsp;</span>Conclusion</a></span></li>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "In this exercise, we will study a theory for how the visual system might learn to represent visual information. The visual system must extract useful information from the complex and highly redundant visual input it receives. The receptive fields of simple cells in the primary visual cortex (V1) can be characterized as being spatially localized, oriented, and bandpass. This means that simple cells are sensitive to visual stimuli presented at a specific location and orientation in the visual field. They are also selective for a range of spatial frequencies. \n",
    "\n",
    "We aim to understand response properties of visual neurons by considering their relationship to the statistical structure of natural images in terms of efficient coding. To accomplish this, we will consider that the visual system learns a \"sparse code\" for natural images. A sparse code is one in which only a small number of neurons in V1 are active at any given time, meaning that the neurons only respond to certain features or patterns in the image.\n",
    "\n",
    "The exercise is based on the work by [Olshausen, B. A., & Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583), 607–609.](https://www.nature.com/articles/381607a0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Image representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by assuming that an image $I(x,y)$ can be represented as a linear superposition of (not necessarily orthogonal) basis functions $\\phi_i(x,y)$:\n",
    "\n",
    "$$\n",
    "I(x,y) = \\sum_{i=1}^{M} a_i \\, \\phi_i(x,y)\n",
    "$$\n",
    "\n",
    "The set of basis functions $\\{\\phi_i\\}_{i=1}^{M}$ determines the image representation (or *code*).  \n",
    "The coefficients $a_i$ are image-dependent variables that change from one image to the next.\n",
    "\n",
    "In vectorized form (for discrete image patches), this can be written as:\n",
    "\n",
    "$$\n",
    "\\mathbf{I} = \\sum_{i=1}^{M} a_i \\boldsymbol{\\phi}_i\n",
    "\\quad \\text{or equivalently} \\quad\n",
    "\\mathbf{I} = \\Phi \\mathbf{a}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Run the code cell below to import the required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "\n",
    "#NOTE: perhaps you need into install cv2:\n",
    "#!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: Visualizing Gabor Filters\n",
    "\n",
    "As a warm-up, we will depict several Gabor filters (also known as *Gabor wavelets* or *Gabor kernels*).  \n",
    "Gabor filters are widely used in image processing to extract features such as edges and textures, and they provide a good phenomenological model of receptive fields of simple cells in primary visual cortex (V1).\n",
    "\n",
    "A Gabor filter consists of:\n",
    "\n",
    "- A **Gaussian envelope**, which determines the spatial extent and shape of the filter.\n",
    "- A **sinusoidal carrier wave**, which determines its frequency and orientation selectivity.\n",
    "\n",
    "The two-dimensional Gabor filter is defined as:\n",
    "\n",
    "$$\n",
    "G(x,y) =\n",
    "\\exp\\left(\n",
    "-\\frac{x'^2 + \\gamma^2 y'^2}{2\\sigma^2}\n",
    "\\right)\n",
    "\\cos\\left(\n",
    "2\\pi \\frac{x'}{\\lambda} + \\phi\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "where the rotated coordinates are given by\n",
    "\n",
    "$$\n",
    "x' = x \\cos\\theta + y \\sin\\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "y' = -x \\sin\\theta + y \\cos\\theta\n",
    "$$\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "- $x, y$ : spatial coordinates  \n",
    "- $\\sigma$ : standard deviation of the Gaussian envelope  \n",
    "- $\\lambda$ : wavelength of the sinusoidal carrier  \n",
    "- $\\theta$ : orientation of the filter  \n",
    "- $\\gamma$ : spatial aspect ratio (ellipticity of the Gaussian)  \n",
    "- $\\phi$ : phase offset  \n",
    "\n",
    "---\n",
    "\n",
    "### Task\n",
    "\n",
    "Implement four Gabor filters with orientations:\n",
    "\n",
    "$$\n",
    "\\theta \\in \\{0^\\circ, 45^\\circ, 90^\\circ, 135^\\circ\\}\n",
    "$$\n",
    "\n",
    "using the following parameters:\n",
    "\n",
    "- Kernel size: $(30, 30)$  \n",
    "- Gaussian standard deviation: $\\sigma = 3.0$  \n",
    "- Wavelength: $\\lambda = 10$  \n",
    "- Spatial aspect ratio: $\\gamma = 0.5$  \n",
    "- Phase: $\\phi = 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelwidth = 30 \n",
    "\n",
    "gabor = []\n",
    "for i in range(4):\n",
    "    # TODO: use OpenCV to define a Gabor Kernel with the desired parameters (~1 line):\n",
    "    gabor_kernel = \n",
    "    gabor.append(gabor_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,1+i)\n",
    "    plt.title(r\"$\\theta=$\"+str(i*45)+r\"$^\\circ$\")\n",
    "    plt.imshow(gabor[i], cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D plot (as shown in the lecture)\n",
    "\n",
    "%matplotlib widget\n",
    "# Note: if the above line fails, try replacing `%matplotlib widget` with `%matplotlib notebook`\n",
    "\n",
    "from matplotlib import cm\n",
    "X = np.arange(kernelwidth+1)\n",
    "Y = np.arange(kernelwidth+1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "surf = ax.plot_surface(X, Y, gabor[i], cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the code below to download the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from original paper source at http://www.rctn.org/bruno/sparsenet/\n",
    "# Note you can also use curl, if wget is not installed (e.g. on MacOS)\n",
    "#!curl  \"-O\" \"http://www.rctn.org/bruno/sparsenet/IMAGES.mat\"\n",
    "#!curl  \"-O\" \"http://www.rctn.org/bruno/sparsenet/IMAGES_RAW.mat\"\n",
    "!wget \"https://www.rctn.org/bruno/sparsenet/IMAGES.mat\"\n",
    "!wget \"https://www.rctn.org/bruno/sparsenet/IMAGES_RAW.mat\"\n",
    "mat_images = sio.loadmat('IMAGES.mat')\n",
    "imgs = mat_images['IMAGES']\n",
    "mat_images_raw = sio.loadmat('IMAGES_RAW.mat')\n",
    "imgs_raw = mat_images_raw['IMAGESr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the dimensions?\n",
    "np.shape(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the code below to visualize raw images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot examle natural images\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imgs_raw[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Natural Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply each of the pre-defined Gabor Kernels to a single image from the dataset and visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = imgs_raw[:, :, 0]\n",
    "out = []\n",
    "for i in range(4):\n",
    "    # TODO: use OpenCV to apply each of the pre-defined Gabor Kernels to the selected single image (~1 line):\n",
    "    out_image = \n",
    "    out.append(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,1+i)\n",
    "    plt.title(r\"$\\theta=$\"+str(i*45)+r\"$^\\circ$\")\n",
    "    plt.imshow(out[i], cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images patches\n",
    "\n",
    "# Simulation constants\n",
    "H, W, num_images = imgs_raw.shape\n",
    "patchs_list = []\n",
    "\n",
    "# TODO: specify the number of parameters (eg. 15000) and path size (eg. 16 x 16) (~2 lines):\n",
    "num_patches = \n",
    "w, h =\n",
    "\n",
    "\n",
    "pl=[]\n",
    "\n",
    "# Generate image patches\n",
    "for patch in tqdm(range(num_patches)):\n",
    "    # Get the coordinates of the upper left corner of for cropping images randomly.\n",
    "    beginx = np.random.randint(0, W-w-1)\n",
    "    beginy = np.random.randint(0, H-h-1)\n",
    "    \n",
    "    # TODO: Get index of a random image from the dataset (~1 line):\n",
    "    idx = \n",
    "    \n",
    "    img_cropped = imgs_raw[beginy:beginy+h, beginx:beginx+w, idx]\n",
    "    \n",
    "    \n",
    "    patchs_list.append(img_cropped.flatten())\n",
    "    \n",
    "    img_c=imgs[beginy:beginy+h, beginx:beginx+w, idx]\n",
    "    pl.append(img_c.flatten())\n",
    "    \n",
    "processed_patches=np.array(pl)\n",
    "\n",
    "patches = np.array(patchs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider **Principal Component Analysis (PCA)**, an unsupervised learning method that finds an orthogonal basis for the data by identifying directions of maximal variance.\n",
    "\n",
    "Given zero-mean data, PCA finds a set of mutually orthogonal basis functions $\\{\\phi_i\\}$ such that the projected coefficients\n",
    "\n",
    "$$\n",
    "a_i = \\boldsymbol{\\phi}_i^\\top \\mathbf{x}\n",
    "$$\n",
    "\n",
    "capture the maximum possible variance subject to orthogonality constraints.\n",
    "\n",
    "The first principal component solves\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}_1 =\n",
    "\\arg\\max_{\\|\\boldsymbol{\\phi}\\|=1}\n",
    "\\mathrm{Var}(\\boldsymbol{\\phi}^\\top \\mathbf{x}),\n",
    "$$\n",
    "\n",
    "and each subsequent component maximizes variance while remaining orthogonal to the previous components.\n",
    "\n",
    "The resulting coefficients are pairwise decorrelated:\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(a_i, a_j) = 0\n",
    "\\quad \\text{for } i \\neq j.\n",
    "$$\n",
    "\n",
    "Equivalently, assuming zero-mean data,\n",
    "\n",
    "$$\n",
    "\\langle a_i a_j \\rangle = 0\n",
    "\\quad \\text{for } i \\neq j,\n",
    "$$\n",
    "\n",
    "where $\\langle \\cdot \\rangle$ denotes expectation over the data distribution.\n",
    "\n",
    "---\n",
    "\n",
    "PCA is commonly used for dimensionality reduction by retaining only the leading principal components that explain the largest fraction of variance. In image processing, PCA can be applied to image p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the PCA and plot the resulting filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize the PCA with the given number of components (~1 line):\n",
    "pca = \n",
    "# TODO: fit the generated patches to the ICA (~1 line):\n",
    "\n",
    "# TODO: get components from the PCA (~1 line):\n",
    "pca_filters = \n",
    "\n",
    "# plot filters\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in tqdm(range(n_comp)):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(np.reshape(pca_filters[i], (w, h)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"PCA\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that receptive fields found by PCA are not localized and the vast majority do not at all resemble cortical tuning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Sparse coding network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a computational model to simulate the learning of a sparse code for natural image patches. We assume that neurons in V1 start with random feedforward connections to the input, and that learning updates these connections to encourage **sparse** activity patterns in the code.\n",
    "\n",
    "The search for a sparse code can be formulated as an optimization problem by minimizing the cost function\n",
    "\n",
    "$$\n",
    "E(\\mathbf{a},\\Phi)\n",
    "=\n",
    "\\underbrace{\\left\\|\\mathbf{I}-\\Phi \\mathbf{a}\\right\\|_2^2}_{\\text{reconstruction error}}\n",
    "+\n",
    "\\lambda\\,\n",
    "\\underbrace{\\sum_{i=1}^{M} \\left|a_i\\right|}_{\\text{sparsity penalty}}.\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "Here, $\\lambda>0$ controls the trade-off between reconstruction fidelity and sparsity. The first term measures how accurately the coefficients $\\mathbf{a}$ and dictionary $\\Phi$ reconstruct the input patch $\\mathbf{I}$. The second term penalizes representations in which activity is spread across many coefficients, favoring codes in which only a few coefficients are active.\n",
    "\n",
    "---\n",
    "\n",
    "### Inference and Learning\n",
    "\n",
    "For a fixed dictionary $\\Phi$, we infer sparse coefficients $\\mathbf{a}$ using an iterative **proximal gradient** (ISTA-style) update: a gradient step on the reconstruction error followed by **soft-thresholding** (the proximal operator of the $\\ell_1$ penalty). For a step size $\\eta>0$, the update is\n",
    "\n",
    "$$\n",
    "\\mathbf{a}^{(t+\\!1)}\n",
    "=\n",
    "\\mathcal{S}_{\\eta\\lambda}\n",
    "\\!\\left(\n",
    "\\mathbf{a}^{(t)} + \\eta\\,\\Phi^\\top\\big(\\mathbf{I}-\\Phi \\mathbf{a}^{(t)}\\big)\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "where the soft-thresholding operator is applied elementwise:\n",
    "\n",
    "$$\n",
    "\\mathcal{S}_{\\theta}(x) = \\mathrm{sign}(x)\\,\\max(|x|-\\theta,\\,0).\n",
    "$$\n",
    "\n",
    "After the coefficients have (approximately) converged for a given batch of patches, we update the dictionary $\\Phi$ by gradient descent on the reconstruction error:\n",
    "\n",
    "$$\n",
    "\\Phi \\leftarrow \\Phi + \\eta_\\Phi\\,(\\mathbf{I}-\\Phi\\mathbf{a})\\,\\mathbf{a}^\\top,\n",
    "$$\n",
    "\n",
    "followed by a column-wise normalization of $\\Phi$ to keep the dictionary elements well-scaled.\n",
    "\n",
    "---\n",
    "\n",
    "### Sparse Coding Network (Architecture)\n",
    "\n",
    "Implement a sparse coding network with:\n",
    "- **Input:** a randomly sampled $16\\times 16$ image patch, vectorized as $\\mathbf{I}\\in\\mathbb{R}^{256}$.\n",
    "- **Code layer:** $M=25$ units that produce a sparse representation $\\mathbf{a}\\in\\mathbb{R}^{25}$.\n",
    "- **Dictionary:** $\\Phi \\in \\mathbb{R}^{256\\times 25}$ maps code coefficients back to the input space.\n",
    "\n",
    "*Note:* The Local Competitive Algorithm (LCA) proposed by Rozell et al. (2008) implements a closely related inference objective using continuous-time dynamics with lateral inhibition. In this exercise we use the simpler discrete-time proximal-gradient (thresholding) inference shown above.\n",
    "\n",
    "For details on LCA, see:\n",
    "Sparse coding via thresholding and local competition in neural circuits by Rozell, Johnson, Baraniuk, and Olshausen\n",
    "https://pubmed.ncbi.nlm.nih.gov/18439138/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCodingNetwork:\n",
    "    def __init__(self, num_inputs, num_units, batch_size, lr_a=1e-2, lr_Phi=1e-2, lmda=5e-3):\n",
    "        # TODO: initialize the learning rate of a and Phi as well as the regularization parameter (trivial, ~3 lines):\n",
    "        self.lr_a = \n",
    "        self.lr_Phi = \n",
    "        self.lmda = \n",
    "        \n",
    "        # TODO: initialize the number of inputs and units as well as the batch size (trivial, ~3 lines):\n",
    "        self.num_inputs = \n",
    "        self.num_units = \n",
    "        self.batch_size = \n",
    "        \n",
    "        # weights initialization\n",
    "        Phi = np.random.randn(self.num_inputs, self.num_units).astype(np.float32)\n",
    "        self.Phi = Phi * np.sqrt(1/self.num_units)\n",
    "        self.initialize_states()\n",
    "    \n",
    "    def initialize_states(self):\n",
    "        self.a = np.zeros((self.batch_size, self.num_units))\n",
    "        \n",
    "    def normalize_columns(self):\n",
    "        self.Phi = self.Phi / np.maximum(np.linalg.norm(self.Phi, ord=2, axis=0, keepdims=True), 1e-8)\n",
    "\n",
    "    def soft_thresholding_func(self, x, lmda):\n",
    "        \"\"\" Soft thresholding function of S(x)=|x| \"\"\" \n",
    "        return np.maximum(x - lmda, 0) - np.maximum(-x - lmda, 0)\n",
    "\n",
    "    def calculate_total_error(self, error):\n",
    "        recon_error = np.mean(error**2)\n",
    "        sparsity_a = self.lmda*np.mean(np.abs(self.a)) \n",
    "        return recon_error + sparsity_a\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        # Updates                \n",
    "        error = inputs - self.a @ self.Phi.T\n",
    "        \n",
    "        a = self.a + self.lr_a * error @ self.Phi\n",
    "        self.a = self.soft_thresholding_func(a, self.lmda)\n",
    "\n",
    "        \n",
    "        if training:  \n",
    "            error = inputs - self.a @ self.Phi.T\n",
    "            dPhi = error.T @ self.a\n",
    "            self.Phi += self.lr_Phi * dPhi\n",
    "\n",
    "\n",
    "            \n",
    "        return error, self.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Run simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify the simulation constants and initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation constants\n",
    "H, W, num_images = imgs.shape\n",
    "\n",
    "# TODO: specify the number of iterations (eg. 100) maximum number of simulation time (eg. 1000s) and batch size (eg. 250) (design choice, ~3 lines):\n",
    "num_iter =  \n",
    "nt_max =  \n",
    "batch_size =  \n",
    "\n",
    "# TODO: specify the image patch size (eg. 16) and the number of neurons (eg. 25) (design choice, ~2 lines):\n",
    "sz =  \n",
    "num_units =  \n",
    "\n",
    "num_inputs = sz**2\n",
    "eps = 1e-2 # small value which determines convergence\n",
    "error_list = [] # List to save errors\n",
    "\n",
    "# TODO: initialize the SparseCodingNetwork with the desired numuber of inputs, units and batch size (~1 line):\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement code to run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "for iter_ in tqdm(range(num_iter)):\n",
    "    # Get the coordinates of the upper left corner of cropping image randomly.\n",
    "    beginx = np.random.randint(0, W - sz + 1, batch_size)\n",
    "    beginy = np.random.randint(0, H - sz + 1, batch_size)\n",
    "\n",
    "    inputs_list = []\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        # TODO: Get index of a random image from the dataset (~1 line):\n",
    "        idx =\n",
    "\n",
    "        img = imgs[:, :, idx]\n",
    "        crop = img[beginy[i]:beginy[i] + sz, beginx[i]:beginx[i] + sz].flatten()\n",
    "        inputs_list.append(crop - np.mean(crop))\n",
    "\n",
    "    inputs = np.asarray(inputs_list, dtype=np.float32)  # Input image patches\n",
    "\n",
    "    # TODO: Reset (initialize) states of the model (~1 line):\n",
    "\n",
    "    # TODO: Normalize weights (columns) (~1 line):  # (or \"rows\" if you keep the old name)\n",
    "\n",
    "    # TODO: Initialize the a (activity of neurons) (~1 line):\n",
    "    a_tm1 =  # should be a copy\n",
    "\n",
    "    for t in range(nt_max):\n",
    "        # TODO: Update a without updating weights (set training to False) (~1 line):\n",
    "        error, a =\n",
    "\n",
    "        # TODO: Compute the difference between current and previous a (~1 line):\n",
    "        da =\n",
    "\n",
    "        da_norm = np.linalg.norm(da, ord=2) / (eps + np.linalg.norm(a_tm1, ord=2))\n",
    "        a_tm1 = a\n",
    "\n",
    "        if da_norm < eps:\n",
    "            # TODO: Update a with weights update (set training to True) (~1 line):\n",
    "            error, a =\n",
    "            break\n",
    "\n",
    "        if t == nt_max - 1:\n",
    "            print(\"Error at patch:\", iter_)\n",
    "            print(da_norm)\n",
    "            break\n",
    "\n",
    "    error_list.append(model.calculate_total_error(error))\n",
    "\n",
    "    if iter_ % 100 == 99:\n",
    "        print(\n",
    "            \"iter: \" + str(iter_ + 1) + \"/\" + str(num_iter) +\n",
    "            \", Moving error:\", np.mean(error_list[iter_ - 99:iter_ + 1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Evaluate performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the following code to plot the error across the iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.plot(np.arange(len(error_list)), np.array(error_list))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the following code to plot the resulting receptive fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in tqdm(range(num_units)):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(np.reshape(model.Phi[:, i], (sz, sz)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Receptive fields\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The presented results show that the sparse model learns to extract simple features from natural images, these receptive fields are similar to the receptive fields of simple cells in the visual cortex. The model provides a plausible explanation for how the visual system might learn to represent complex visual information with a relatively small number of neurons. The result suggests that this type of sparse coding may be a general principle of sensory processing in the brain.\n",
    "\n",
    "For more detail on this topic, please see the source work by [Olshausen, B. A., & Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583), 607–609.](https://www.nature.com/articles/381607a0). \n",
    "\n",
    "##### Congratulations! You have finished this week's problem set on learning a sparse code for natural images!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NX-414",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "342px",
    "left": "22px",
    "top": "110px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
